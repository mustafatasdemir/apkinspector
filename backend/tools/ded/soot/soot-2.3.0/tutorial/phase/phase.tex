
\documentclass{article}
\usepackage{fullpage}
\usepackage{html}
\usepackage{longtable}

\title{Soot phase options}
\author{Patrick Lam (\htmladdnormallink{plam@sable.mcgill.ca}{mailto:plam@sable.mcgill.ca})\\
Feng Qian (\htmladdnormallink{fqian@sable.mcgill.ca}{mailto:fqian@sable.mcgill.ca})\\
Ond\v{r}ej Lhot\'ak (\htmladdnormallink{olhotak@sable.mcgill.ca}{mailto:olhotak@sable.mcgill.ca})\\
John Jorgensen\\ 
}

\begin{document}

\maketitle

Soot supports the powerful---but initially confusing---notion of
``phase options''.  This document aims to clear up the confusion so
you can exploit the power of phase options.

Soot's execution is divided into a number of phases.  For example,
{\tt JimpleBody}s are built by a phase called {\tt jb}, which is
itself comprised of subphases, such as the aggregation of local
variables ({\tt jb.a}).

Phase options provide a way for you to
change the behaviour of a phase from the Soot command-line.  They take
the form {\tt -p }{\em phase}.{\em name} 
{\em option}:{\em value}.  For instance,
to instruct Soot to use original names in Jimple, we would invoke Soot
like this:
\begin{verbatim}
java soot.Main foo -p jb use-original-names:true
\end{verbatim}
Multiple option-value pairs may be specified in a single {\tt -p} option
separated by commas. For example,
\begin{verbatim}
java soot.Main foo -p cg.spark verbose:true,on-fly-cg:true
\end{verbatim}

There are five types of phase options:
\begin{enumerate}
\item Boolean options take the values
``true'' and ``false''; if you specify the name of a boolean option without adding a value for it, ``true'' is assumed.
\item
Multi-valued options take a value from a set of allowed values
specific to that option.
\item Integer options
take an integer value. 
\item Floating point options take a 
floating point number as their value. 
\item String options take an arbitrary
string as their value.
\end{enumerate}

Each option has a default value which is used if the option is not
specified on the command line.

All phases and subphases accept the option ``{\tt enabled}'', which
must be ``{\tt true}'' for the phase or subphase to execute. To save
you some typing, the pseudo-options ``{\tt on}'' and ``{\tt off}''
are equivalent to ``{\tt enabled:true}'' and ``{\tt enabled:false}'',
respectively. In addition, specifying any options for a phase
automatically enables that phase.

\paragraph{Adding your own subphases}

\noindent
\par
Within Soot, each phase is implemented by a {\tt Pack}. The {\tt Pack}
is a collection of transformers, each corresponding to a subphase of
the phase implemented by the {\tt Pack}. When the {\tt Pack} is
called, it executes each of its transformers in order.

Soot transformers are usually instances of classes that extend 
{\tt BodyTransformer} or {\tt SceneTransformer}.  In either case, the
transformer class must override the {\tt internalTransform} method,
providing an implementation which carries out some transformation on
the code being analyzed.

To add a transformer to some {\tt Pack} without modifying Soot itself,
create your own class which changes the contents of the {\tt Pack}s to
meet your requirements and then calls {\tt soot.Main}.

\vspace{3ex}

The remainder of this document describes the transformations belonging
to Soot's various {\tt Pack}s and their corresponding phase
options.

\tableofcontents


\section{Jimple Body Creation ({\tt jb})}

Jimple Body Creation creates a {\tt JimpleBody} for each input
method, using either coffi, to read {\tt .class} files, or the
jimple parser, to read {\tt .jimple} files.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Use Original Names ({\tt use-original-names})]
(default value: {\tt false})




Retain the original names for local variables when the source
includes those names.  Otherwise, Soot gives variables generic
names based on their types.



\item[Preserve source-level annotations ({\tt preserve-source-annotations})]
(default value: {\tt false})




Preserves annotations of retention type SOURCE. (for
everything but package and local variable annotations) 



\end{description}

\subsection{Local Splitter ({\tt jb.ls})}

The Local Splitter identifies DU-UD webs for local variables and
introduces new variables so that each disjoint web is associated
with a single local.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Jimple Local Aggregator ({\tt jb.a})}


\par

The Jimple Local Aggregator removes some unnecessary copies by
combining local variables. Essentially, it finds definitions
which have only a single use and, if it is safe to do so, removes
the original definition after replacing the use with the
definition's right-hand side.

\par

At this stage in {\tt JimpleBody} construction, local
aggregation serves largely to remove the copies to and from stack
variables which simulate load and store instructions in the
original bytecode.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Only Stack Locals ({\tt only-stack-locals})]
(default value: {\tt true})




Only aggregate locals that represent stack locations in the
original bytecode.  (Stack locals can be distinguished in Jimple
by the \$ character with which their names begin.)



\end{description}

\subsection{Unused Local Eliminator ({\tt jb.ule})}

The Unused Local Eliminator removes any unused locals from the
method.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Type Assigner ({\tt jb.tr})}

The Type Assigner gives local variables types which will
accommodate the values stored in them over the course of the
method.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Use older type assigner ({\tt use-older-type-assigner})]
(default value: {\tt false})




This enables the older type assigner that was in use until May 2008.
The current type assigner is a reimplementation by Ben Bellamy
that uses an entirely new and faster algorithm which always assigns
the most narrow type possible. If compare-type-assigners is on,
this option causes the older type assigner to execute first.
(Otherwise the newer one is executed first.)



\item[Compare type assigners ({\tt compare-type-assigners})]
(default value: {\tt false})




Enables comparison (both runtime and results) of Ben Bellamy's type assigner with the
older type assigner that was in Soot.



\end{description}

\subsection{Unsplit-originals Local Packer ({\tt jb.ulp})}

The Unsplit-originals Local Packer executes only when the
`{\tt use-original-names}' option is chosen for the
`{\tt jb}' phase.  The Local Packer attempts to minimize
the number of local variables required in a method by reusing the
same variable for disjoint DU-UD webs. Conceptually, it is the
inverse of the Local Splitter.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Unsplit Original Locals ({\tt unsplit-original-locals})]
(default value: {\tt true})




Use the variable names in the original source as a guide when
determining how to share local variables among non-interfering
variable usages. This recombines named locals which were split by
the Local Splitter.



\end{description}

\subsection{Local Name Standardizer ({\tt jb.lns})}

The Local Name Standardizer assigns generic names to local variables.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Only Stack Locals ({\tt only-stack-locals})]
(default value: {\tt false})




Only standardizes the names of variables that represent stack
locations in the original bytecode. This becomes the default when
the `{\tt use-original-names}' option is specified for
the `{\tt jb}' phase.



\end{description}

\subsection{Copy Propagator ({\tt jb.cp})}

This phase performs cascaded copy propagation.  
    
If the propagator encounters situations of the form: 

\begin{quote}\begin{verbatim}

  A: a = ...; 
    ...
  B:  x = a;
    ...
  C: ... = ... x; 

\end{verbatim}\end{quote}

where {\tt a} and {\tt x} are each defined only once (at
{\tt A} and {\tt B}, respectively), then it can propagate
immediately without checking between {\tt B} and {\tt C}
for redefinitions of {\tt a}.  In
this case the propagator is global.
        
Otherwise, if {\tt a} has multiple definitions then the
propagator checks for redefinitions and propagates copies
only within extended basic blocks.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Only Regular Locals ({\tt only-regular-locals})]
(default value: {\tt false})




Only propagate copies through ``regular'' locals, that is,
those declared in the source bytecode.



\item[Only Stack Locals ({\tt only-stack-locals})]
(default value: {\tt true})




Only propagate copies through locals that represent stack locations in
the original bytecode.



\end{description}

\subsection{Dead Assignment Eliminator ({\tt jb.dae})}

The Dead Assignment Eliminator eliminates assignment statements
to locals whose values are not subsequently used, unless
evaluating the right-hand side of the assignment may cause
side-effects.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Only Stack Locals ({\tt only-stack-locals})]
(default value: {\tt true})




Only eliminate dead assignments to locals that represent stack
locations in the original bytecode.



\end{description}

\subsection{Post-copy propagation Unused Local Eliminator ({\tt jb.cp-ule})}

This phase removes any locals that are unused after copy propagation.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Local Packer ({\tt jb.lp})}

The Local Packer attempts to minimize the number of local
variables required in a method by reusing the same variable for
disjoint DU-UD webs. Conceptually, it is the inverse of the
Local Splitter.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\item[Unsplit Original Locals ({\tt unsplit-original-locals})]
(default value: {\tt false})




Use the variable names in the original source as a guide when
determining how to share local variables across non-interfering
variable usages. This recombines named locals which were split by
the Local Splitter. 



\end{description}

\subsection{Nop Eliminator ({\tt jb.ne})}

The Nop Eliminator removes {\tt nop} statements from the method.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Unreachable Code Eliminator ({\tt jb.uce})}

The Unreachable Code Eliminator removes unreachable code and
traps whose catch blocks are empty.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Remove unreachable traps ({\tt remove-unreachable-traps})]
(default value: {\tt false})




Remove exception table entries when none of the protected instructions can
throw the exception being caught.



\end{description}

\subsection{Trap Tightener ({\tt jb.tt})}

The Trap Tightener changes the area protected by each exception handler,
so that it begins with the first instruction in the old protected
area which is actually capable of throwing an exception caught by the
handler, and ends just after the last instruction in the old
protected area which can throw an exception caught by the
handler.  This reduces the chance of producing unverifiable code
as a byproduct of pruning exceptional control flow within CFGs.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\section{Java To Jimple Body Creation ({\tt jj})}

Jimple Body Creation creates a {\tt JimpleBody} for each input
method, using polyglot, to read {\tt .java} files.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Use Original Names ({\tt use-original-names})]
(default value: {\tt true})




Retain the original names for local variables when the source
includes those names.  Otherwise, Soot gives variables generic
names based on their types.



\end{description}

\subsection{Local Splitter ({\tt jj.ls})}

The Local Splitter identifies DU-UD webs for local variables and
introduces new variables so that each disjoint web is associated
with a single local.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{Jimple Local Aggregator ({\tt jj.a})}


\par

The Jimple Local Aggregator removes some unnecessary copies by
combining local variables. Essentially, it finds definitions
which have only a single use and, if it is safe to do so, removes
the original definition after replacing the use with the
definition's right-hand side.

\par

At this stage in {\tt JimpleBody} construction, local
aggregation serves largely to remove the copies to and from stack
variables which simulate load and store instructions in the
original bytecode.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Only Stack Locals ({\tt only-stack-locals})]
(default value: {\tt true})




Only aggregate locals that represent stack locations in the
original bytecode.  (Stack locals can be distinguished in Jimple
by the \$ character with which their names begin.)



\end{description}

\subsection{Unused Local Eliminator ({\tt jj.ule})}

The Unused Local Eliminator removes any unused locals from the
method.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Type Assigner ({\tt jj.tr})}

The Type Assigner gives local variables types which will
accommodate the values stored in them over the course of the
method.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{Unsplit-originals Local Packer ({\tt jj.ulp})}

The Unsplit-originals Local Packer executes only when the
`{\tt use-original-names}' option is chosen for the
`{\tt jb}' phase.  The Local Packer attempts to minimize
the number of local variables required in a method by reusing the
same variable for disjoint DU-UD webs. Conceptually, it is the
inverse of the Local Splitter.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\item[Unsplit Original Locals ({\tt unsplit-original-locals})]
(default value: {\tt false})




Use the variable names in the original source as a guide when
determining how to share local variables among non-interfering
variable usages. This recombines named locals which were split by
the Local Splitter.



\end{description}

\subsection{Local Name Standardizer ({\tt jj.lns})}

The Local Name Standardizer assigns generic names to local variables.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Only Stack Locals ({\tt only-stack-locals})]
(default value: {\tt false})




Only standardizes the names of variables that represent stack
locations in the original bytecode. This becomes the default when
the `{\tt use-original-names}' option is specified for
the `{\tt jb}' phase.



\end{description}

\subsection{Copy Propagator ({\tt jj.cp})}

This phase performs cascaded copy propagation.  
    
If the propagator encounters situations of the form: 

\begin{quote}\begin{verbatim}

  A: a = ...; 
    ...
  B:  x = a;
    ...
  C: ... = ... x; 

\end{verbatim}\end{quote}

where {\tt a} and {\tt x} are each defined only once (at
{\tt A} and {\tt B}, respectively), then it can propagate
immediately without checking between {\tt B} and {\tt C}
for redefinitions of {\tt a}.  In
this case the propagator is global.
        
Otherwise, if {\tt a} has multiple definitions then the
propagator checks for redefinitions and propagates copies
only within extended basic blocks.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Only Regular Locals ({\tt only-regular-locals})]
(default value: {\tt false})




Only propagate copies through ``regular'' locals, that is,
those declared in the source bytecode.



\item[Only Stack Locals ({\tt only-stack-locals})]
(default value: {\tt true})




Only propagate copies through locals that represent stack locations in
the original bytecode.



\end{description}

\subsection{Dead Assignment Eliminator ({\tt jj.dae})}

The Dead Assignment Eliminator eliminates assignment statements
to locals whose values are not subsequently used, unless
evaluating the right-hand side of the assignment may cause
side-effects.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Only Stack Locals ({\tt only-stack-locals})]
(default value: {\tt true})




Only eliminate dead assignments to locals that represent stack
locations in the original bytecode.



\end{description}

\subsection{Post-copy propagation Unused Local Eliminator ({\tt jj.cp-ule})}

This phase removes any locals that are unused after copy propagation.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Local Packer ({\tt jj.lp})}

The Local Packer attempts to minimize the number of local
variables required in a method by reusing the same variable for
disjoint DU-UD webs. Conceptually, it is the inverse of the
Local Splitter.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\item[Unsplit Original Locals ({\tt unsplit-original-locals})]
(default value: {\tt false})




Use the variable names in the original source as a guide when
determining how to share local variables across non-interfering
variable usages. This recombines named locals which were split by
the Local Splitter. 



\end{description}

\subsection{Nop Eliminator ({\tt jj.ne})}

The Nop Eliminator removes {\tt nop} statements from the method.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Unreachable Code Eliminator ({\tt jj.uce})}

The Unreachable Code Eliminator removes unreachable code and
traps whose catch blocks are empty.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\section{Call Graph Constructor ({\tt cg})}

The Call Graph Constructor computes a call graph for whole
program analysis. When this pack finishes, a call graph is
available in the Scene.  The different phases in this pack are
different ways to construct the call graph. Exactly one phase in
this pack must be enabled; Soot will raise an error otherwise.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Safe forName ({\tt safe-forname})]
(default value: {\tt false})



When a program calls
Class.forName(), the named class is resolved, and its static initializer
executed. In many cases, it cannot be determined statically which
class will be loaded, and which static initializer executed. When this
option is set to true, Soot will conservatively assume that any static
initializer could be executed. This may make the call graph very large.
When this option is set to false, any calls to Class.forName() for which
the class cannot be determined statically are assumed to call no
static initializers.



\item[Safe newInstance ({\tt safe-newinstance})]
(default value: {\tt false})



When a program calls
Class.newInstance(), a new object is created and its constructor
executed. Soot does not determine statically which
type of object will be created, and which constructor executed. When this
option is set to true, Soot will conservatively assume that any constructor
could be executed. This may make the call graph very large.
When this option is set to false, any calls to Class.newInstance()
are assumed not to call the constructor of the created object.



\item[Verbose ({\tt verbose})]
(default value: {\tt false})



Due to the effects of native methods and reflection, it may not always be possible to construct a fully conservative call graph. Setting this option to true causes Soot to point out the parts of the call graph that may be incomplete, so that they can be checked by hand.
                                        


\item[JDK version ({\tt jdkver})]
(default value: {\tt 3})



This option sets the JDK version of the standard library being analyzed so that Soot can simulate the native methods in the specific version of the library. The default, 3, refers to Java 1.3.x.


\item[All Application Class Methods Reachable ({\tt all-reachable})]
(default value: {\tt false})



When this option is false, the call graph is built starting at a set of entry points, and only methods reachable from those entry points are processed. Unreachable methods will not have any call graph edges generated out of them. Setting this option to true makes Soot consider all methods of application classes to be reachable, so call edges are generated for all of them. This leads to a larger call graph. For program visualization purposes, it is sometimes desirable to include edges from unreachable methods; although these methods are unreachable in the version being analyzed, they may become reachable if the program is modified.


\item[Implicit Entry Points ({\tt implicit-entry})]
(default value: {\tt true})



When this option is true, methods that are called implicitly by the VM are considered entry points of the call graph. When it is false, these methods are not considered entry points, leading to a possibly incomplete call graph.


\item[Trim Static Initializer Edges ({\tt trim-clinit})]
(default value: {\tt true})



The call graph contains an edge
from each statement that could trigger execution of a static initializer to that
static initializer. However, each static initializer is triggered only once.
When this option is enabled, after the call graph is built, an intra-procedural
analysis is performed to detect static initializer edges leading to methods
that must have already been executed. Since these static initializers cannot be
executed again, the corresponding call graph edges are removed from the call graph.



\end{description}

\subsection{Class Hierarchy Analysis ({\tt cg.cha})}
This phase uses Class Hierarchy Analysis to generate a call graph.

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Verbose ({\tt verbose})]
(default value: {\tt false})



Setting this option to true causes Soot to print out statistics about the call graph computed by this phase, such as the number of methods determined to be reachable.


\end{description}

\subsection{Spark ({\tt cg.spark})}
Spark is a flexible points-to analysis framework. Aside from building a call graph, it also generates information about the targets of pointers. For details about Spark, please see \htmladdnormallink{Ondrej Lhotak's M.Sc. thesis}{http://www.sable.mcgill.ca/publications/thesis/\#olhotakMastersThesis}.

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsubsection{Spark General Options}


\paragraph{Accepted phase options:} 

\begin{description}

\item[Verbose ({\tt verbose})]
(default value: {\tt false})




When this option is set to true, Spark prints detailed information about its execution.
        


\item[Ignore Types Entirely ({\tt ignore-types})]
(default value: {\tt false})




When this option is set to true, all parts of Spark completely ignore
declared types of variables and casts.
        


\item[Force Garbage Collections ({\tt force-gc})]
(default value: {\tt false})




When this option is set to true, calls to System.gc() will be made at
various points to allow memory usage to be measured.
        


\item[Pre Jimplify ({\tt pre-jimplify})]
(default value: {\tt false})




When this option is set to true, Spark converts all available methods to Jimple
before starting the points-to analysis. This allows the Jimplification
time to be separated from the points-to time. However, it increases the
total time and memory requirement, because all methods are Jimplified,
rather than only those deemed reachable by the points-to analysis.
        


\end{description}

\subsubsection{Spark Pointer Assignment Graph Building Options}


\paragraph{Accepted phase options:} 

\begin{description}

\item[VTA ({\tt vta})]
(default value: {\tt false})




Setting VTA to true has the effect of setting field-based,
types-for-sites, and simplify-sccs to true, and on-fly-cg to false,
to simulate Variable Type
Analysis, described in \htmladdnormallink{our OOPSLA 2000 paper}{http://www.sable.mcgill.ca/publications/papers/\#oopsla2000}. Note that the
algorithm differs from the original VTA in that it handles array
elements more precisely.
        


\item[RTA ({\tt rta})]
(default value: {\tt false})




Setting RTA to true sets types-for-sites to true, and causes Spark to use
a single points-to set for all variables, giving \htmladdnormallink{Rapid Type
Analysis}{http://doi.acm.org/10.1145/236337.236371}.
        


\item[Field Based ({\tt field-based})]
(default value: {\tt false})




When this option is set to true, fields are represented by variable
(Green) nodes, and the object that the field belongs to is ignored
(all objects are lumped together), giving a field-based analysis. Otherwise, fields are represented by
field reference (Red) nodes, and the objects that they belong to are
distinguished, giving a field-sensitive analysis.
        


\item[Types For Sites ({\tt types-for-sites})]
(default value: {\tt false})




When this option is set to true, types rather than allocation sites are
used as the elements of the points-to sets.
        


\item[Merge String Buffer ({\tt merge-stringbuffer})]
(default value: {\tt true})




When this option is set to true, all allocation sites creating
{\tt java.lang.StringBuffer} objects are grouped together as a single
allocation site.
        


\item[Propagate All String Constants ({\tt string-constants})]
(default value: {\tt false})




When this option is set to false, Spark only distinguishes string constants that
may be the name of a class loaded dynamically using reflection, and all other
string constants are lumped together into a single string constant node.
Setting this option to true causes all string constants to be propagated
individually.
        


\item[Simulate Natives ({\tt simulate-natives})]
(default value: {\tt true})




When this option is set to true, the effects of native methods in the standard Java class library are simulated.
        


\item[Treat EMPTY as Alloc ({\tt empties-as-allocs})]
(default value: {\tt false})




When this option is set to true, Spark treats references to EMPTYSET, EMPTYMAP, and 
EMPTYLIST as allocation sites for HashSet, HashMap and LinkedList objects respectively, and references to Hashtable.emptyIterator as allocation sites for Hashtable.EmptyIterator. This enables subsequent analyses to differentiate different uses of Java's immutable empty collections.
        


\item[Simple Edges Bidirectional ({\tt simple-edges-bidirectional})]
(default value: {\tt false})




When this option is set to true, all edges connecting variable (Green)
nodes are made bidirectional, as in \htmladdnormallink{Steensgaard's analysis}{http://doi.acm.org/10.1145/237721.237727}.
        


\item[On Fly Call Graph ({\tt on-fly-cg})]
(default value: {\tt true})




When this option is set to true, the call graph is computed on-the-fly
as points-to information is computed. Otherwise, an initial
CHA approximation to the call graph is used.
        


\end{description}

\subsubsection{Spark Pointer Assignment Graph Simplification Options}


\paragraph{Accepted phase options:} 

\begin{description}

\item[Simplify Offline ({\tt simplify-offline})]
(default value: {\tt false})




When this option is set to true, variable (Green) nodes which form
single-entry subgraphs (so they must have the same points-to set) are
merged before propagation begins.
        


\item[Simplify SCCs ({\tt simplify-sccs})]
(default value: {\tt false})




When this option is set to true, variable (Green) nodes which form
strongly-connected components (so they must have the same points-to set)
are merged before propagation begins.
        


\item[Ignore Types For SCCs ({\tt ignore-types-for-sccs})]
(default value: {\tt false})




When this option is set to true, when collapsing strongly-connected
components, nodes forming SCCs are collapsed regardless of their declared type.
The collapsed SCC is given the most general type of all the nodes in the
component.

When this option is set to false, only edges connecting nodes of the
same type are considered when detecting SCCs.

This option has no effect unless {\tt simplify-sccs} is true.
        


\end{description}

\subsubsection{Spark Points-To Set Flowing Options}


\paragraph{Accepted phase options:} 

\begin{description}

\item[Propagator ({\tt propagator})]
(default value: {\tt worklist})




This option tells Spark which propagation algorithm to use.
        



Possible values:\\
\begin{longtable}{p{1in}p{4in}}

{\tt iter }
&

Iter is a simple, iterative algorithm, which propagates everything until the
graph does not change.
\\

{\tt worklist }
&

Worklist is a worklist-based algorithm that tries
to do as little work as possible. This is currently the fastest algorithm.
\\

{\tt cycle }
&
This algorithm finds cycles in the PAG on-the-fly. It is not yet finished.\\

{\tt merge }
&

Merge is an algorithm that merges all concrete field (yellow) nodes with their corresponding
field reference (red) nodes. This algorithm is not yet finished.
\\

{\tt alias }
&

Alias is an alias-edge based algorithm. This algorithm tends to take
the least memory for very large problems, because it does not represent
explicitly points-to sets of fields of heap objects.
\\

{\tt none }
&

None means that propagation is not done; the graph is only built and
simplified. This is useful if an external solver is being used to perform the
propagation.
\\

\end{longtable}


\item[Set Implementation ({\tt set-impl})]
(default value: {\tt double})




Select an implementation of points-to sets for Spark to use.




Possible values:\\
\begin{longtable}{p{1in}p{4in}}

{\tt hash }
&

Hash is an implementation based on Java's built-in hash-set.
\\

{\tt bit }
&

Bit is an implementation using a bit vector.
\\

{\tt hybrid }
&

Hybrid is an implementation that keeps an explicit list of up to
16 elements, and switches to a bit-vector when the set gets
larger than this.
\\

{\tt array }
&

Array is an implementation that keeps the elements of the
points-to set in a sorted array. Set membership is tested using
binary search, and set union and intersection are computed using
an algorithm based on the merge step from merge sort.
\\

{\tt heintze }
&
Heintze's representation has elements represented by a bit-vector + a small
									'overflow' list of some maximum number of elements.  The bit-vectors can be shared
									by multiple points-to sets, while the overflow lists are not.
								\\

{\tt sharedlist }
&
Shared List stores its elements in a linked list, and might share
									its tail with other similar points-to sets.
								\\

{\tt double }
&

Double is an implementation that itself uses a pair of sets for
each points-to set. The first set in the pair stores new pointed-to
objects that have not yet been propagated, while the second set stores
old pointed-to objects that have been propagated and need not be
reconsidered. This allows the propagation algorithms to be incremental,
often speeding them up significantly.
\\

\end{longtable}


\item[Double Set Old ({\tt double-set-old})]
(default value: {\tt hybrid})




Select an implementation for sets of old objects in the double
points-to set implementation.

This option has no effect unless Set Implementation is set to double.
        



Possible values:\\
\begin{longtable}{p{1in}p{4in}}

{\tt hash }
&

Hash is an implementation based on Java's built-in hash-set.
\\

{\tt bit }
&

Bit is an implementation using a bit vector.
\\

{\tt hybrid }
&

Hybrid is an implementation that keeps an explicit list of up to
16 elements, and switches to a bit-vector when the set gets
larger than this.
\\

{\tt array }
&

Array is an implementation that keeps the elements of the
points-to set in a sorted array. Set membership is tested using
binary search, and set union and intersection are computed using
an algorithm based on the merge step from merge sort.
\\

{\tt heintze }
&
Heintze's representation has elements represented by a bit-vector + a small
									'overflow' list of some maximum number of elements.  The bit-vectors can be shared
									by multiple points-to sets, while the overflow lists are not.
								\\

{\tt sharedlist }
&
Shared List stores its elements in a linked list, and might share
									its tail with other similar points-to sets.
								\\

\end{longtable}


\item[Double Set New ({\tt double-set-new})]
(default value: {\tt hybrid})




Select an implementation for sets of new objects in the double
points-to set implementation.

This option has no effect unless Set Implementation is set to double.
        



Possible values:\\
\begin{longtable}{p{1in}p{4in}}

{\tt hash }
&

Hash is an implementation based on Java's built-in hash-set.
\\

{\tt bit }
&

Bit is an implementation using a bit vector.
\\

{\tt hybrid }
&

Hybrid is an implementation that keeps an explicit list of up to
16 elements, and switches to a bit-vector when the set gets
larger than this.
\\

{\tt array }
&

Array is an implementation that keeps the elements of the
points-to set in a sorted array. Set membership is tested using
binary search, and set union and intersection are computed using
an algorithm based on the merge step from merge sort.
\\

{\tt heintze }
&
Heintze's representation has elements represented by a bit-vector + a small
									'overflow' list of some maximum number of elements.  The bit-vectors can be shared
									by multiple points-to sets, while the overflow lists are not.
								\\

{\tt sharedlist }
&
Shared List stores its elements in a linked list, and might share
									its tail with other similar points-to sets.
								\\

\end{longtable}


\end{description}

\subsubsection{Spark Output Options}


\paragraph{Accepted phase options:} 

\begin{description}

\item[Dump HTML ({\tt dump-html})]
(default value: {\tt false})




When this option is set to true, a browseable HTML representation of the
pointer assignment graph is output to a file called {\tt pag.jar} after the analysis completes. Note
that this representation is typically very large.
        


\item[Dump PAG ({\tt dump-pag})]
(default value: {\tt false})




When this option is set to true, a representation of the pointer assignment graph
suitable for processing with other solvers (such as the BDD-based solver) is
output before the analysis begins.
        


\item[Dump Solution ({\tt dump-solution})]
(default value: {\tt false})




When this option is set to true, a representation of the resulting points-to
sets is dumped. The format is similar to that of the Dump PAG
option, and is therefore suitable for comparison with the results of other
solvers.
        


\item[Topological Sort ({\tt topo-sort})]
(default value: {\tt false})




When this option is set to true, the representation dumped by the
Dump PAG option
is dumped with the variable (green) nodes in (pseudo-)topological order.

This option has no effect unless Dump PAG is true.
        


\item[Dump Types ({\tt dump-types})]
(default value: {\tt true})




When this option is set to true, the representation dumped by the
Dump PAG option
includes type information for all nodes.

This option has no effect unless Dump PAG is true.
        


\item[Class Method Var ({\tt class-method-var})]
(default value: {\tt true})




When this option is set to true, the representation dumped by the
Dump PAG option
represents nodes by numbering each class, method, and variable within
the method separately, rather than assigning a single integer to each
node.

This option has no effect unless Dump PAG is true.  Setting Class
Method Var to true has the effect of setting Topological Sort to
false.
        


\item[Dump Answer ({\tt dump-answer})]
(default value: {\tt false})




When this option is set to true, the computed reaching types for each variable are
dumped to a file, so that they can be compared with the results of
other analyses (such as the old VTA).
        


\item[Add Tags ({\tt add-tags})]
(default value: {\tt false})




        When this option is set to true, the results of the analysis are encoded within
tags and printed with the resulting Jimple code.

        


\item[Calculate Set Mass ({\tt set-mass})]
(default value: {\tt false})




When this option is set to true, Spark computes and prints various
cryptic statistics about the size of the points-to sets computed.
        


\end{description}

\subsubsection{Context-sensitive refinement}


\paragraph{Accepted phase options:} 

\begin{description}

\item[Demand-driven refinement-based context-sensitive points-to analysis ({\tt cs-demand})]
(default value: {\tt false})




When this option is set to true, Manu Sridharan's demand-driven,
refinement-based points-to analysis (PLDI 06) is applied after Spark
was run.
        					


\item[Maximal traversal ({\tt traversal})]
(default value: {\tt 75000})




Make the analysis traverse at most this number of nodes per query.
This quota is evenly shared between multiple passes (see next option).
        					


\item[Maximal number of passes ({\tt passes})]
(default value: {\tt 10})




Perform at most this number of refinement iterations.
Each iteration traverses at most ( traverse / passes ) nodes.
        					


\end{description}

\subsection{Paddle ({\tt cg.paddle})}
Paddle is a BDD-based interprocedural analysis framework. It includes points-to analysis, call graph construction, and various client analyses.

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsubsection{Paddle General Options}


\paragraph{Accepted phase options:} 

\begin{description}

\item[Verbose ({\tt verbose})]
(default value: {\tt false})




When this option is set to true, Paddle prints detailed information about its execution.
        


\item[Configuration ({\tt conf})]
(default value: {\tt ofcg})




Selects the configuration of points-to analysis and call graph construction
to be used in Paddle.
        



Possible values:\\
\begin{longtable}{p{1in}p{4in}}

{\tt ofcg }
&

Performs points-to analysis and builds call graph together, on-the-fly.
\\

{\tt cha }
&

Builds only a call graph using Class Hieararchy Analysis, and performs no
points-to analysis.
\\

{\tt cha-aot }
&

First builds a call graph using CHA, then uses the call graph in a fixed-call-graph points-to analysis.
\\

{\tt ofcg-aot }
&

First builds a call graph on-the-fly during a points-to analysis, then
uses the resulting call graph to perform a second points-to analysis
with a fixed call graph.
\\

{\tt cha-context-aot }
&

First builds a call graph using CHA, then makes it context-sensitive using
the technique described by Calman and Zhu in PLDI 04,
then uses the call graph in a fixed-call-graph points-to analysis.
\\

{\tt ofcg-context-aot }
&

First builds a call graph on-the-fly during a points-to analysis, then
makes it context-sensitive using the technique described by Calman and
Zhu in PLDI 04, then uses the resulting call graph to perform a second
points-to analysis with a fixed call graph.
\\

{\tt cha-context }
&

First builds a call graph using CHA, then makes it context-sensitive using
the technique described by Calman and Zhu in PLDI 04. Does not produce
points-to information.
\\

{\tt ofcg-context }
&

First builds a call graph on-the-fly during a points-to analysis, then
makes it context-sensitive using the technique described by Calman and
Zhu in PLDI 04. Does not perform a subsequent points-to analysis.
\\

\end{longtable}


\item[Use BDDs ({\tt bdd})]
(default value: {\tt false})




                                                        Causes Paddle to use BDD versions of its components
        


\item[Variable ordering ({\tt order})]
(default value: {\tt 32})




                                        Selects one of the BDD variable orderings hard-coded in Paddle.
                


\item[Dynamic reordering ({\tt dynamic-order})]
(default value: {\tt false})




                                        Allows the BDD package to perform dynamic variable ordering.
                


\item[Profile ({\tt profile})]
(default value: {\tt false})




Turns on JeddProfiler for profiling BDD operations.
        


\item[Verbose GC ({\tt verbosegc})]
(default value: {\tt false})




Print memory usage at each BDD garbage collection.
        


\item[Worklist Implementation ({\tt q})]
(default value: {\tt auto})




Select the implementation of worklists to be used in Paddle.
        



Possible values:\\
\begin{longtable}{p{1in}p{4in}}

{\tt auto }
&

When the bdd option is true, the BDD-based worklist implementation will be used.
When the bdd option is false, the Traditional worklist implementation will be used.
\\

{\tt trad }
&

Normal worklist queue implementation
\\

{\tt bdd }
&

BDD-based queue implementation
\\

{\tt debug }
&

An implementation of worklists that includes both traditional and BDD-based
implementations, and signals an error whenever their contents differ.
\\

{\tt trace }
&

A worklist implementation that prints out all tuples added to every worklist.
\\

{\tt numtrace }
&

A worklist implementation that prints out the number of tuples added to
each worklist after each operation.
\\

\end{longtable}


\item[Backend ({\tt backend})]
(default value: {\tt auto})




This option tells Paddle which implementation of BDDs to use.
        



Possible values:\\
\begin{longtable}{p{1in}p{4in}}

{\tt auto }
&

When the bdd option is true, the BuDDy backend will be used.
When the bdd option is false, the backend will be set to none, to avoid
loading any BDD backend.
\\

{\tt buddy }
&

Use BuDDy implementation of BDDs.
\\

{\tt cudd }
&

Use CUDD implementation of BDDs.
\\

{\tt sable }
&
Use SableJBDD implementation of BDDs.\\

{\tt javabdd }
&

Use JavaBDD implementation of BDDs.
\\

{\tt none }
&

Don't use any BDD backend. Any attempted use of BDDs will cause Paddle to crash.
\\

\end{longtable}


\item[BDD Nodes ({\tt bdd-nodes})]
(default value: {\tt 0})




This option specifies the number of BDD nodes to be used by the BDD backend.
A value of 0 causes the backend to start with one million nodes, and allocate
more as required. A value other than zero causes the backend to start with
the specified size, and prevents it from ever allocating any more nodes.
        


\item[Ignore Types Entirely ({\tt ignore-types})]
(default value: {\tt false})




When this option is set to true, all parts of Paddle completely ignore
declared types of variables and casts.
        


\item[Pre Jimplify ({\tt pre-jimplify})]
(default value: {\tt false})




When this option is set to true, Paddle converts all available methods to Jimple
before starting the points-to analysis. This allows the Jimplification
time to be separated from the points-to time. However, it increases the
total time and memory requirement, because all methods are Jimplified,
rather than only those deemed reachable by the points-to analysis.
        


\end{description}

\subsubsection{Paddle Context Sensitivity Options}


\paragraph{Accepted phase options:} 

\begin{description}

\item[Context abstraction ({\tt context})]
(default value: {\tt insens})




This option tells Paddle which level of context-sensitivity to use in constructing the call graph.




Possible values:\\
\begin{longtable}{p{1in}p{4in}}

{\tt insens }
&

Builds a context-insensitive call graph.
\\

{\tt 1cfa }
&

Builds a 1-CFA call graph.
\\

{\tt kcfa }
&

Builds a k-CFA call graph.
\\

{\tt objsens }
&

Builds an object-sensitive call graph.
\\

{\tt kobjsens }
&

Builds a context-sensitive call graph where the context is a string of up to
k receiver objects.
\\

{\tt uniqkobjsens }
&

Builds a context-sensitive call graph where the context is a string of up to
k unique receiver objects. If the receiver of a call already appears in the
context string, the context string is just reused as is.
\\

{\tt threadkobjsens }
&

Experimental option for thread-entry-point sensitivity.
\\

\end{longtable}


\item[Context length (k) ({\tt k})]
(default value: {\tt 2})




                                        The maximum length of call string or receiver object string used as context.
                


\item[Context-sensitive Heap Locations ({\tt context-heap})]
(default value: {\tt false})




When this option is set to true, the context-sensitivity level that is set
for the context-sensitive call graph and for pointer variables is also used
to model heap locations context-sensitively. When this option is false,
heap locations are modelled context-insensitively regardless of the
context-sensitivity level.
        


\end{description}

\subsubsection{Paddle Pointer Assignment Graph Building Options}


\paragraph{Accepted phase options:} 

\begin{description}

\item[RTA ({\tt rta})]
(default value: {\tt false})




Setting RTA to true sets types-for-sites to true, and causes Paddle to use
a single points-to set for all variables, giving \htmladdnormallink{Rapid Type
Analysis}{http://doi.acm.org/10.1145/236337.236371}.
        


\item[Field Based ({\tt field-based})]
(default value: {\tt false})




When this option is set to true, fields are represented by variable
(Green) nodes, and the object that the field belongs to is ignored
(all objects are lumped together), giving a field-based analysis. Otherwise, fields are represented by
field reference (Red) nodes, and the objects that they belong to are
distinguished, giving a field-sensitive analysis.
        


\item[Types For Sites ({\tt types-for-sites})]
(default value: {\tt false})




When this option is set to true, types rather than allocation sites are
used as the elements of the points-to sets.
        


\item[Merge String Buffer ({\tt merge-stringbuffer})]
(default value: {\tt true})




When this option is set to true, all allocation sites creating
{\tt java.lang.StringBuffer} objects are grouped together as a single
allocation site.
        


\item[Propagate All String Constants ({\tt string-constants})]
(default value: {\tt false})




When this option is set to false, Paddle only distinguishes string constants that
may be the name of a class loaded dynamically using reflection, and all other
string constants are lumped together into a single string constant node.
Setting this option to true causes all string constants to be propagated
individually.
        


\item[Simulate Natives ({\tt simulate-natives})]
(default value: {\tt true})




When this option is set to true, the effects of native methods in the standard Java class library are simulated.
        


\item[Global Nodes in Simulated Natives ({\tt global-nodes-in-natives})]
(default value: {\tt false})




The simulations of native methods such as System.arraycopy() use
temporary local variable nodes. Setting this switch to true causes them
to use global variable nodes instead, reducing precision. The switch
exists only to make it possible to measure this effect on precision;
there is no other practical reason to set it to true.
        


\item[Simple Edges Bidirectional ({\tt simple-edges-bidirectional})]
(default value: {\tt false})




When this option is set to true, all edges connecting variable (Green)
nodes are made bidirectional, as in \htmladdnormallink{Steensgaard's analysis}{http://doi.acm.org/10.1145/237721.237727}.
        


\item[this Pointer Assignment Edge ({\tt this-edges})]
(default value: {\tt false})




When constructing a call graph on-the-fly during points-to analysis, Paddle
normally propagates only those receivers that cause a method to be invoked
to the this pointer of the method. When this option is set to true, however,
Paddle instead models flow of receivers as an assignnment edge from the
receiver at the call site to the this pointer of the method, reducing
precision.
        


\item[Precise newInstance ({\tt precise-newinstance})]
(default value: {\tt true})




    Normally, newInstance() calls are treated as if they may return an object
    of any type. Setting this option to true causes them to be treated as if
    they return only objects of the type of some dynamic class.
            


\end{description}

\subsubsection{Paddle Points-To Set Flowing Options}


\paragraph{Accepted phase options:} 

\begin{description}

\item[Propagator ({\tt propagator})]
(default value: {\tt auto})




This option tells Paddle which propagation algorithm to use.
        



Possible values:\\
\begin{longtable}{p{1in}p{4in}}

{\tt auto }
&

When the bdd option is true, the Incremental BDD propagation algorithm will be used.
When the bdd option is false, the Worklist propagation algorithm will be used.
\\

{\tt iter }
&

Iter is a simple, iterative algorithm, which propagates everything until the
graph does not change.
\\

{\tt worklist }
&

Worklist is a worklist-based algorithm that tries
to do as little work as possible. This is currently the fastest algorithm.
\\

{\tt alias }
&

Alias is an alias-edge based algorithm. This algorithm tends to take
the least memory for very large problems, because it does not represent
explicitly points-to sets of fields of heap objects.
\\

{\tt bdd }
&

BDD is a propagator that stores points-to sets in binary decision diagrams.
\\

{\tt incbdd }
&

A propagator that stores points-to sets in binary decision diagrams, and propagates them incrementally.
\\

\end{longtable}


\item[Set Implementation ({\tt set-impl})]
(default value: {\tt double})




Select an implementation of points-to sets for Paddle to use.




Possible values:\\
\begin{longtable}{p{1in}p{4in}}

{\tt hash }
&

Hash is an implementation based on Java's built-in hash-set.
\\

{\tt bit }
&

Bit is an implementation using a bit vector.
\\

{\tt hybrid }
&

Hybrid is an implementation that keeps an explicit list of up to
16 elements, and switches to a bit-vector when the set gets
larger than this.
\\

{\tt array }
&

Array is an implementation that keeps the elements of the
points-to set in a sorted array. Set membership is tested using
binary search, and set union and intersection are computed using
an algorithm based on the merge step from merge sort.
\\

{\tt heintze }
&
Heintze's representation has elements represented by a bit-vector + a small
									'overflow' list of some maximum number of elements.  The bit-vectors can be shared
									by multiple points-to sets, while the overflow lists are not.
								\\

{\tt double }
&

Double is an implementation that itself uses a pair of sets for
each points-to set. The first set in the pair stores new pointed-to
objects that have not yet been propagated, while the second set stores
old pointed-to objects that have been propagated and need not be
reconsidered. This allows the propagation algorithms to be incremental,
often speeding them up significantly.
\\

\end{longtable}


\item[Double Set Old ({\tt double-set-old})]
(default value: {\tt hybrid})




Select an implementation for sets of old objects in the double
points-to set implementation.

This option has no effect unless Set Implementation is set to double.
        



Possible values:\\
\begin{longtable}{p{1in}p{4in}}

{\tt hash }
&

Hash is an implementation based on Java's built-in hash-set.
\\

{\tt bit }
&

Bit is an implementation using a bit vector.
\\

{\tt hybrid }
&

Hybrid is an implementation that keeps an explicit list of up to
16 elements, and switches to a bit-vector when the set gets
larger than this.
\\

{\tt array }
&

Array is an implementation that keeps the elements of the
points-to set in a sorted array. Set membership is tested using
binary search, and set union and intersection are computed using
an algorithm based on the merge step from merge sort.
\\

{\tt heintze }
&
Heintze's representation has elements represented by a bit-vector + a small
									'overflow' list of some maximum number of elements.  The bit-vectors can be shared
									by multiple points-to sets, while the overflow lists are not.
								\\

\end{longtable}


\item[Double Set New ({\tt double-set-new})]
(default value: {\tt hybrid})




Select an implementation for sets of new objects in the double
points-to set implementation.

This option has no effect unless Set Implementation is set to double.
        



Possible values:\\
\begin{longtable}{p{1in}p{4in}}

{\tt hash }
&

Hash is an implementation based on Java's built-in hash-set.
\\

{\tt bit }
&

Bit is an implementation using a bit vector.
\\

{\tt hybrid }
&

Hybrid is an implementation that keeps an explicit list of up to
16 elements, and switches to a bit-vector when the set gets
larger than this.
\\

{\tt array }
&

Array is an implementation that keeps the elements of the
points-to set in a sorted array. Set membership is tested using
binary search, and set union and intersection are computed using
an algorithm based on the merge step from merge sort.
\\

{\tt heintze }
&
Heintze's representation has elements represented by a bit-vector + a small
									'overflow' list of some maximum number of elements.  The bit-vectors can be shared
									by multiple points-to sets, while the overflow lists are not.
								\\

\end{longtable}


\end{description}

\subsubsection{Paddle Output Options}


\paragraph{Accepted phase options:} 

\begin{description}

\item[Print Context Counts ({\tt context-counts})]
(default value: {\tt false})




Causes Paddle to print the number of contexts for each method and
call edge, and the number of equivalence classes of contexts for
each variable node.
        


\item[Print Context Counts (Totals only) ({\tt total-context-counts})]
(default value: {\tt false})




Causes Paddle to print the number of contexts and number of context
equivalence classes.
        


\item[Method Context Counts (Totals only) ({\tt method-context-counts})]
(default value: {\tt false})




Causes Paddle to print the number of contexts and number of context
equivalence classes split out by method. Requires total-context-counts to also be turned on.
        


\item[Calculate Set Mass ({\tt set-mass})]
(default value: {\tt false})




When this option is set to true, Paddle computes and prints various
cryptic statistics about the size of the points-to sets computed.
        


\item[Number nodes ({\tt number-nodes})]
(default value: {\tt true})




When printing debug information about nodes, this option causes the node number
of each node to be printed.
        


\end{description}

\section{Whole Shimple Transformation Pack ({\tt wstp})}


\par

Soot can perform whole-program analyses.  In whole-shimple mode, Soot
applies the contents of the Whole-Shimple Transformation Pack to the
scene as a whole after constructing a call graph for the program.

\par

In an unmodified copy of Soot the Whole-Shimple Transformation
Pack is empty.
        

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\section{Whole Shimple Optimization Pack ({\tt wsop})}


\par

If Soot is running in whole shimple mode and the Whole-Shimple
Optimization Pack is enabled, the pack's transformations are
applied to the scene as a whole after construction of the call
graph and application of any enabled Whole-Shimple
Transformations.

\par

In an unmodified copy of Soot the Whole-Shimple Optimization
Pack is empty.
        

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\section{Whole-Jimple Transformation Pack ({\tt wjtp})}


\par

Soot can perform whole-program analyses.  In whole-program mode,
Soot applies the contents of the Whole-Jimple Transformation Pack
to the scene as a whole after constructing a call graph for the
program.
                        

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Transactional Transformation ({\tt wjtp.tn})}

The Transactional Transformation find transactional regions in
Java programs and prepares them for transactional execution on
both optimistic and pessimistic JVMs.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\item[Locking Scheme ({\tt locking-scheme})]
(default value: {\tt medium-grained})



Selects the granularity of the generated lock allocation



Possible values:\\
\begin{longtable}{p{1in}p{4in}}

{\tt medium-grained }
&

Try to identify transactional regions that can employ a dynamic lock to
increase parallelism.  All side effects must be protected by a single object.
This locking scheme aims to approximate typical Java Monitor usage.
\\

{\tt coarse-grained }
&

Insert static objects into the program for synchronization.  One object will be
used for each group of conflicting synchronized regions.  This locking scheme
achieves code-level locking.
\\

{\tt single-static }
&

Insert one static object into the program for synchronization for all
transactional regions.  This locking scheme is for research purposes.
\\

{\tt leave-original }
&

Analyse the existing lock structure of the program, but do not change it.  With
one of the print options, this can be useful for comparison between the original
program and one of the generated locking schemes.
\\

\end{longtable}


\item[Perform Deadlock Avoidance ({\tt avoid-deadlock})]
(default value: {\tt true})




Perform Deadlock Avoidance by enforcing a lock ordering where necessary.



\item[Use Open Nesting ({\tt open-nesting})]
(default value: {\tt true})




Use an open nesting model, where inner transactions are allowed to commit
independently of any outer transaction.



\item[Perform May-Happen-in-Parallel Analysis ({\tt do-mhp})]
(default value: {\tt true})




Perform a May-Happen-in-Parallel analysis to assist in allocating locks.



\item[Perform Local Objects Analysis ({\tt do-tlo})]
(default value: {\tt true})




Perform a Local-Objects analysis to assist in allocating locks.



\item[Print Topological Graph ({\tt print-graph})]
(default value: {\tt false})




Print a topological graph of the program's transactions in the format used by the graphviz package.



\item[Print Table ({\tt print-table})]
(default value: {\tt false})




Print a table of information about the program's transactions.



\item[Print Debugging Info ({\tt print-debug})]
(default value: {\tt false})




Print debugging info, including every statement visited.



\end{description}

\section{Whole-Jimple Optimization Pack ({\tt wjop})}


\par

If Soot is running in whole program mode and the Whole-Jimple
Optimization Pack is enabled, the pack's transformations are
applied to the scene as a whole after construction of the call
graph and application of any enabled Whole-Jimple
Transformations.
                        

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{Static Method Binder ({\tt wjop.smb})}

The Static Method Binder statically binds monomorphic call
sites. That is, it searches the call graph for virtual method
invocations that can be determined statically to call only a single
implementation of the called method.  Then it replaces such virtual
invocations with invocations of a static copy of the single called
implementation.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\item[Insert Null Checks ({\tt insert-null-checks})]
(default value: {\tt true})




Insert a check that, before invoking the static copy of the
target method, throws a {\tt NullPointerException} if the
receiver object is null.  This ensures that static method binding does
not eliminate exceptions which would have occurred in its absence.



\item[Insert Redundant Casts ({\tt insert-redundant-casts})]
(default value: {\tt true})





\par

Insert extra casts for the Java bytecode verifier.  If the target
method uses its {\tt this} parameter, a reference to the
receiver object must be passed to the static copy of the target
method. The verifier may complain if the declared type of the
receiver parameter does not match the type implementing the
target method.

\par

Say, for example, that {\tt Singer} is an interface declaring
the {\tt sing()} method and that the call graph shows all
receiver objects at a particular call site,
{\tt singer.sing()} (with {\tt singer} declared as a
{\tt Singer}) are in fact {\tt Bird} objects ({\tt Bird}
being a class that implements {\tt Singer}). The virtual call
{\tt singer.sing()} is effectively replaced with the static
call {\tt Bird.staticsing(singer)}. {\tt Bird.staticsing()}
may perform operations on its parameter which are only allowed on
{\tt Bird}s, rather than {\tt Singer}s.  The Insert
Redundant Casts option inserts a cast of {\tt singer} to the
{\tt Bird} type, to prevent complaints from the verifier.



\item[Allowed Modifier Changes ({\tt allowed-modifier-changes})]
(default value: {\tt unsafe})




Specify which changes in visibility modifiers
are allowed.  




Possible values:\\
\begin{longtable}{p{1in}p{4in}}

{\tt unsafe }
&

Modify the visibility on code so that all inlining is permitted.
\\

{\tt safe }
&

Preserve the exact meaning of the analyzed program.
\\

{\tt none }
&

Change no modifiers whatsoever.
\\

\end{longtable}


\end{description}

\subsection{Static Inliner ({\tt wjop.si})}

The Static Inliner visits all call sites in the call graph in a
bottom-up fashion, replacing monomorphic calls with inlined
copies of the invoked methods.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Reconstruct Jimple body after inlining ({\tt rerun-jb})]
(default value: {\tt true})




When a method with array parameters is inlined, its variables may need to
be assigned different types than they had in the original method to produce
compilable code. When this option is set, Soot re-runs the Jimple Body pack
on each method body which has had another method inlined into it so that
the typing algorithm can reassign the types.



\item[Insert Null Checks ({\tt insert-null-checks})]
(default value: {\tt true})




Insert, before the inlined body of the target method, a check
that throws a {\tt NullPointerException} if the receiver
object is null.  This ensures that inlining will not eliminate
exceptions which would have occurred in its absence.



\item[Insert Redundant Casts ({\tt insert-redundant-casts})]
(default value: {\tt true})





\par

Insert extra casts for the Java bytecode verifier.  The verifier
may complain if the inlined method uses {\tt this} and the
declared type of the receiver of the call being inlined is
different from the type implementing the target method being
inlined.

\par

Say, for example, that {\tt Singer} is an interface declaring
the {\tt sing()} method and that the call graph shows that all
receiver objects at a particular call site,
{\tt singer.sing()} (with {\tt singer} declared as a
{\tt Singer}) are in fact {\tt Bird} objects ({\tt Bird}
being a class that implements {\tt Singer}). The
implementation of {\tt Bird.sing()} may perform operations on
{\tt this} which are only allowed on {\tt Bird}s, rather
than {\tt Singer}s.  The Insert Redundant Casts option ensures that
this cannot lead to verification errors, by inserting a cast of
{\tt bird} to the {\tt Bird} type before inlining the body
of {\tt Bird.sing()}.



\item[Allowed Modifier Changes ({\tt allowed-modifier-changes})]
(default value: {\tt unsafe})




Specify which changes in visibility modifiers
are allowed.  




Possible values:\\
\begin{longtable}{p{1in}p{4in}}

{\tt unsafe }
&

Modify the visibility on code so that all inlining is permitted.
\\

{\tt safe }
&

Preserve the exact meaning of the analyzed program.
\\

{\tt none }
&

Change no modifiers whatsoever.
\\

\end{longtable}


\item[Expansion Factor ({\tt expansion-factor})]
(default value: {\tt 3})




Determines the maximum allowed expansion of a method.  Inlining
will cause the method to grow by a factor of no more than
the Expansion Factor.



\item[Max Container Size ({\tt max-container-size})]
(default value: {\tt 5000})




Determines the maximum number of Jimple statements for a container
method.  If a method has more than this number of Jimple statements,
then no methods will be inlined into it.
                        


\item[Max Inlinee Size ({\tt max-inlinee-size})]
(default value: {\tt 20})




Determines the maximum number of Jimple statements for an inlinee
method.  If a method has more than this number of Jimple statements,
then it will not be inlined into other methods.
                        


\end{description}

\section{Whole-Jimple Annotation Pack ({\tt wjap})}


\par

Some analyses do not transform Jimple body directly, but annotate
statements or values with tags. Whole-Jimple annotation pack provides
a place for annotation-oriented analyses in whole program mode.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Rectangular Array Finder ({\tt wjap.ra})}
 

\par

The Rectangular Array Finder traverses Jimple statements
based on the static call graph, and finds array variables which always
hold rectangular two-dimensional array objects.

\par

In Java, a multi-dimensional array is an array of arrays, which
means the shape of the array can be ragged. Nevertheless, many
applications use rectangular arrays. Knowing that an array is
rectangular can be very helpful in proving safe array bounds
checks.

\par

The Rectangular Array Finder does not change the
program being analyzed. Its results are used by the Array Bound
Checker.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{Unreachable Method Tagger ({\tt wjap.umt})}

\par
Uses the call graph to determine which methods are unreachable and adds color tags so they can be highlighted in a source browser.

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{Unreachable Fields Tagger ({\tt wjap.uft})}

\par
Uses the call graph to determine which fields are unreachable and adds color tags so they can be highlighted in a source browser.

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{Tightest Qualifiers Tagger ({\tt wjap.tqt})}

\par
Determines which methods and fields have qualifiers that could be tightened. For example: if a field or method has the qualifier of public but is only used within the declaring class it could be private. This, this field or method is tagged with color tags so that the results can be highlighted in a source browser.

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{Call Graph Grapher ({\tt wjap.cgg})}

\par
Creates graphical call graph.

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\item[Show Library Methods ({\tt show-lib-meths})]
(default value: {\tt false})






\end{description}

\subsection{Purity Analysis [AM] ({\tt wjap.purity})}

Purity anaysis implemented by Antoine Mine and based on the paper
A Combined Pointer and Purity Analysis for Java Programs by 
Alexandru Salcianu and Martin Rinard.
                    

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\item[Dump one .dot files for each method summary ({\tt dump-summaries})]
(default value: {\tt true})






\item[Dump .dot call-graph annotated with method summaries (huge) ({\tt dump-cg})]
(default value: {\tt false})






\item[Dump one .dot for each intra-procedural method analysis (long) ({\tt dump-intra})]
(default value: {\tt false})






\item[Print analysis results ({\tt print})]
(default value: {\tt true})






\item[Be (quite) verbose ({\tt verbose})]
(default value: {\tt false})






\end{description}

\section{Shimple Control ({\tt shimple})}


\par

Shimple Control sets parameters which apply throughout the
creation and manipulation of Shimple bodies. Shimple is Soot's
SSA representation.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Shimple Node Elimination Optimizations ({\tt node-elim-opt})]
(default value: {\tt true})




          
\par

          Perform some optimizations, such as dead code elimination
          and local aggregation, before/after eliminating nodes.
         
         


\item[Local Name Standardization ({\tt standard-local-names})]
(default value: {\tt false})




            If enabled, the Local Name Standardizer is applied whenever
            Shimple creates new locals.  Normally, Shimple will retain
            the original local names as far as possible and use an
            underscore notation to denote SSA subscripts.  This
            transformation does not otherwise affect Shimple
            behaviour.
          


\item[Extended SSA (SSI) ({\tt extended})]
(default value: {\tt false})




            If enabled, Shimple will created extended SSA (SSI) form.
          


\item[Debugging Output ({\tt debug})]
(default value: {\tt false})




            If enabled, Soot may print out warnings and messages
            useful for debugging the Shimple module.  Automatically
            enabled by the global debug switch.
          


\end{description}

\section{Shimple Transformation Pack ({\tt stp})}

          
\par

            When the Shimple representation is produced, Soot applies the
            contents of the Shimple Transformation Pack to each method
            under analysis.  This pack contains no transformations in an
            unmodified version of Soot.
          
        

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\section{Shimple Optimization Pack ({\tt sop})}

          
\par

            The Shimple Optimization Pack contains transformations that
            perform optimizations on Shimple, Soot's SSA
            representation.
          
        

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{Shimple Constant Propagator and Folder ({\tt sop.cpf})}

            
\par

              A powerful constant propagator and folder based on an
              algorithm sketched by Cytron et al that takes
              conditional control flow into account.  This
              optimization demonstrates some of the benefits of SSA
              -- particularly the fact that Phi nodes represent
              natural merge points in the control flow.
            
          

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Prune Control Flow Graph ({\tt prune-cfg})]
(default value: {\tt true})




              
\par

                Conditional branching statements that are found to
                branch unconditionally (or fall through) are replaced
                with unconditional branches (or removed).  This
                transformation exposes more opportunities for dead
                code removal.
              
            


\end{description}

\section{Jimple Transformation Pack ({\tt jtp})}

Soot applies the contents of the Jimple Transformation Pack to
each method under analysis.  This pack contains no
transformations in an unmodified version of Soot.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\section{Jimple Optimization Pack ({\tt jop})}

When Soot's Optimize option is on, Soot applies the
Jimple Optimization Pack to every {\tt JimpleBody} in
application classes.  This section lists the default
transformations in the Jimple Optimization Pack.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{Common Subexpression Eliminator ({\tt jop.cse})}


\par

The Common Subexpression Eliminator runs an available expressions
analysis on the method body, then eliminates common
subexpressions.


\par

This implementation is especially slow, as it runs on individual
statements rather than on basic blocks.  A better implementation
(which would find most common subexpressions, but not all) would use
basic blocks instead.


\par

This implementation is also slow because the flow universe is
explicitly created; it need not be.  A better implementation
would implicitly compute the kill sets at every node.


\par

Because of its current slowness, this transformation is not
enabled by default.



\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\item[Naive Side Effect Tester ({\tt naive-side-effect})]
(default value: {\tt false})





\par

If Naive Side Effect Tester is {\tt true}, the Common
Subexpression Eliminator uses the conservative side effect
information provided by the {\tt NaiveSideEffectTester} class,
even if interprocedural information about side effects is
available.

\par

The naive side effect analysis is based solely on the information
available locally about a statement. It assumes, for example,
that any method call has the potential to write and read all
instance and static fields in the program.

\par

If Naive Side Effect Tester is set to {\tt false} and Soot is
in whole program mode, then the Common Subexpression
Eliminator uses the side effect information provided by the
{\tt PASideEffectTester} class. {\tt PASideEffectTester}
uses a points-to analysis to
determine which fields and statics may be written or read by a
given statement.

\par

If whole program analysis is not performed, naive side effect
information is used regardless of the setting of
Naive Side Effect Tester.




\end{description}

\subsection{Busy Code Motion ({\tt jop.bcm})}

Busy Code Motion is a straightforward implementation of Partial
Redundancy Elimination. This implementation is not very
aggressive.  Lazy Code Motion is an improved version which
should be used instead of Busy Code Motion.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\item[Naive Side Effect Tester ({\tt naive-side-effect})]
(default value: {\tt false})





\par

If Naive Side Effect Tester is set to {\tt true}, Busy Code
Motion uses the conservative side effect information provided by
the {\tt NaiveSideEffectTester} class, even if interprocedural
information about side effects is available.

\par

The naive side effect analysis is based solely on the information
available locally about a statement. It assumes, for example,
that any method call has the potential to write and read all
instance and static fields in the program.

\par

If Naive Side Effect Tester is set to {\tt false} and Soot is
in whole program mode, then Busy Code Motion uses the side effect
information provided by the {\tt PASideEffectTester}
class. {\tt PASideEffectTester} uses a points-to analysis to
determine which fields and statics may be written or read by a
given statement.

\par

If whole program analysis is not performed, naive side effect
information is used regardless of the setting of
Naive Side Effect Tester.




\end{description}

\subsection{Lazy Code Motion ({\tt jop.lcm})}

Lazy Code Motion is an enhanced version of Busy Code Motion, a
Partial Redundancy Eliminator. Before doing Partial Redundancy Elimination,
this optimization performs loop inversion (turning {\tt while} loops
into {\tt do while} loops inside an {\tt if} statement).
This allows the Partial Redundancy Eliminator
to optimize loop invariants of {\tt while} loops.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\item[Safety ({\tt safety})]
(default value: {\tt safe})




This option controls which fields and statements are candidates
for code motion.




Possible values:\\
\begin{longtable}{p{1in}p{4in}}

{\tt safe }
&

Safe, but only considers moving additions,
subtractions and multiplications.
\\

{\tt medium }
&

Unsafe in multi-threaded programs, as it may reuse the values
read from field accesses.
\\

{\tt unsafe }
&

May violate Java's exception semantics, as it may move or reorder
exception-throwing statements, potentially outside of
{\tt try-catch} blocks.
\\

\end{longtable}


\item[Unroll ({\tt unroll})]
(default value: {\tt true})




If {\tt true}, perform loop inversion before doing the
transformation.



\item[Naive Side Effect Tester ({\tt naive-side-effect})]
(default value: {\tt false})





\par

If Naive Side Effect Tester is set to {\tt true}, Lazy Code
Motion uses the conservative side effect information provided by
the {\tt NaiveSideEffectTester} class, even if interprocedural
information about side effects is available.

\par

The naive side effect analysis is based solely on the information
available locally about a statement. It assumes, for example,
that any method call has the potential to write and read all
instance and static fields in the program.

\par

If Naive Side Effect Tester is set to {\tt false} and Soot is
in whole program mode, then Lazy Code Motion uses the side effect
information provided by the {\tt PASideEffectTester}
class. {\tt PASideEffectTester} uses a points-to analysis to
determine which fields and statics may be written or read by a
given statement.

\par

If whole program analysis is not performed, naive side effect
information is used regardless of the setting of
Naive Side Effect Tester.




\end{description}

\subsection{Copy Propagator ({\tt jop.cp})}


\par

This phase performs cascaded copy propagation.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Only Regular Locals ({\tt only-regular-locals})]
(default value: {\tt false})




Only propagate copies through ``regular'' locals, that is,
those declared in the source bytecode.



\item[Only Stack Locals ({\tt only-stack-locals})]
(default value: {\tt false})




Only propagate copies through locals that represent stack locations in
the original bytecode.



\end{description}

\subsection{Jimple Constant Propagator and Folder ({\tt jop.cpf})}

The Jimple Constant Propagator and Folder evaluates any expressions
consisting entirely of compile-time constants, for example {\tt 2
* 3}, and replaces the expression with the constant result,
in this case {\tt 6}.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Conditional Branch Folder ({\tt jop.cbf})}

The Conditional Branch Folder statically evaluates the
conditional expression of Jimple {\tt if} statements.  If the
condition is identically {\tt true} or
{\tt false}, the Folder replaces the conditional branch
statement with an unconditional {\tt goto} statement.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Dead Assignment Eliminator ({\tt jop.dae})}

The Dead Assignment Eliminator eliminates assignment statements
to locals whose values are not subsequently used, unless
evaluating the right-hand side of the assignment may cause
side-effects.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Only Tag Dead Code ({\tt only-tag})]
(default value: {\tt false})




Only tag dead assignment statements instead of eliminaing them.



\item[Only Stack Locals ({\tt only-stack-locals})]
(default value: {\tt false})




Only eliminate dead assignments to locals that represent stack
locations in the original bytecode.



\end{description}

\subsection{Null Check Eliminator ({\tt jop.nce})}

Replaces statements 'if(x!=null) goto y' with 'goto y' if x is
known to be non-null or with 'nop' if it is known to be null,
etc. Generates dead code and is hence followed by unreachable
code elimination. Disabled by default because it can be
expensive on methods with many locals.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{Unreachable Code Eliminator 1 ({\tt jop.uce1})}

The Unreachable Code Eliminator removes unreachable code and
traps whose catch blocks are empty.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Remove unreachable traps ({\tt remove-unreachable-traps})]
(default value: {\tt false})




Remove exception table entries when none of the protected instructions can
throw the exception being caught.



\end{description}

\subsection{Unconditional Branch Folder 1 ({\tt jop.ubf1})}


\par

The Unconditional Branch Folder removes unnecessary `{\tt goto}'
statements from a {\tt JimpleBody}.

\par

If a {\tt goto} statement's target is the next instruction,
then the statement is removed.  If a {\tt goto}'s target is
another {\tt goto}, with target {\tt y}, then the first
statement's target is changed to {\tt y}.

\par

If some {\tt if} statement's target is a {\tt goto}
statement, then the {\tt if}'s target can be replaced with the
{\tt goto}'s target.

\par

(These situations can result from other optimizations, and branch
folding may itself generate more unreachable code.)


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Unreachable Code Eliminator 2 ({\tt jop.uce2})}

Another iteration of the Unreachable Code Eliminator.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Remove unreachable traps ({\tt remove-unreachable-traps})]
(default value: {\tt false})




Remove exception table entries when none of the protected instructions can
throw the exception being caught.



\end{description}

\subsection{Unconditional Branch Folder 2 ({\tt jop.ubf2})}

Another iteration of the Unconditional Branch Folder.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Unused Local Eliminator ({\tt jop.ule})}

The Unused Local Eliminator phase removes any unused locals from
the method.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\section{Jimple Annotation Pack ({\tt jap})}

The Jimple Annotation Pack contains phases which add annotations
to Jimple bodies individually (as opposed to the Whole-Jimple
Annotation Pack, which adds annotations based on the analysis of
the whole program).
                        

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Null Pointer Checker ({\tt jap.npc})}

The Null Pointer Checker finds instruction which have the potential
to throw {\tt NullPointerException}s and adds annotations
indicating whether or not the pointer being dereferenced can be
determined statically not to be null.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\item[Only Array Ref ({\tt only-array-ref})]
(default value: {\tt false})




Annotate only array-referencing instructions, instead of all
instructions that need null pointer checks.



\item[Profiling ({\tt profiling})]
(default value: {\tt false})





\par

Insert profiling instructions that at runtime count the number of
eliminated safe null pointer checks. The inserted profiling code
assumes the existence of a {\tt MultiCounter} class
implementing the methods invoked. For details, see the
{\tt NullPointerChecker} source code.



\end{description}

\subsection{Null Pointer Colourer ({\tt jap.npcolorer})}

Produce colour tags that the Soot plug-in for Eclipse can use to
highlight null and non-null references.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{Array Bound Checker ({\tt jap.abc})}


\par

The Array Bound Checker performs a static analysis to determine
which array bounds checks may safely be eliminated and then annotates
statements with the results of the analysis.

\par

If Soot is in whole-program mode, the Array Bound Checker can
use the results provided by the Rectangular Array Finder.
                        

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\item[With All ({\tt with-all})]
(default value: {\tt false})





\par

Setting the With All option to true is equivalent to setting each
of With CSE, With Array Ref, With Field Ref,
With Class Field, and  With Rectangular Array to true.
                        


\item[With Common Sub-expressions ({\tt with-cse})]
(default value: {\tt false})





\par

The analysis will consider common subexpressions.  For example,
consider the situation where {\tt r1} is assigned
{\tt a*b}; later, {\tt r2} is assigned {\tt a*b}, where
neither {\tt a} nor {\tt b} have changed between the two
statements. The analysis can conclude that {\tt r2} has the
same value as {\tt r1}. Experiments show that this option can
improve the result slightly.



\item[With Array References ({\tt with-arrayref})]
(default value: {\tt false})





\par

With this option enabled, array references can be considered as
common subexpressions; however, we are more conservative when
writing into an array, because array objects may be aliased. We
also assume that the application is single-threaded or that the
array references occur in a synchronized block. That is, we
assume that an array element may not be changed by other threads
between two array references.



\item[With Field References ({\tt with-fieldref})]
(default value: {\tt false})





\par

The analysis treats field references (static and instance) as
common subexpressions; however, we are more conservative when
writing to a field, because the base of the field reference may
be aliased. We also assume that the application is
single-threaded or that the field references occur in a
synchronized block. That is, we assume that a field may
not be changed by other threads between two field references.



\item[With Class Field ({\tt with-classfield})]
(default value: {\tt false})





\par

This option makes the analysis work on the class level. The
algorithm analyzes {\tt final} or {\tt private} class
fields first. It can recognize the fields that hold array objects
of constant length.  In an application using lots of array
fields, this option can improve the analysis results
dramatically.



\item[With Rectangular Array ({\tt with-rectarray})]
(default value: {\tt false})




This option is used together with {\tt wjap.ra} to make Soot run the whole-program
analysis for rectangular array objects. This analysis is based on the
call graph, and it usually takes a long time. If the application uses
rectangular arrays, these options can improve the analysis
result.



\item[Profiling ({\tt profiling})]
(default value: {\tt false})





\par

Profile the results of array bounds check analysis.  The inserted
profiling code assumes the existence of a {\tt MultiCounter}
class implementing the methods invoked. For details, see the
{\tt ArrayBoundsChecker} source code.



\item[Add Color Tags ({\tt add-color-tags})]
(default value: {\tt false})



Add color tags to the results of the array bounds check analysis.


\end{description}

\subsection{Profiling Generator ({\tt jap.profiling})}


\par

The Profiling Generator inserts the method invocations required
to initialize and to report the results of any profiling
performed by the Null Pointer Checker and Array Bound
Checker. Users of the Profiling Generator must provide a
{\tt MultiCounter} class implementing the methods invoked. For
details, see the {\tt ProfilingGenerator} source code.



\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\item[Not Main Entry ({\tt notmainentry})]
(default value: {\tt false})





\par

Insert the calls to the {\tt MultiCounter} at the
beginning and end of methods with the signature
{\tt long runBenchmark(java.lang.String[])}
instead of the signature
{\tt void main(java.lang.String[])}.



\end{description}

\subsection{Side Effect tagger ({\tt jap.sea})}


\par

The Side Effect Tagger
uses the active invoke graph to produce side-effect attributes, as
described in the \htmladdnormallink{Spark
thesis}{http://www.sable.mcgill.ca/publications/thesis/\#olhotakMastersThesis}, chapter 6.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\item[Build naive dependence graph ({\tt naive})]
(default value: {\tt false})





\par

When set to true, the dependence graph is built with a node for
each statement, without merging the nodes for equivalent
statements. This makes it possible to measure the effect of
merging nodes for equivalent statements on the size of the
dependence graph.



\end{description}

\subsection{Field Read/Write Tagger ({\tt jap.fieldrw})}


\par

The Field Read/Write Tagger uses the active invoke graph to
produce tags indicating which fields may be read or written by
each statement, including invoke statements.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\item[Maximum number of fields ({\tt threshold})]
(default value: {\tt 100})




If a statement reads/writes more than this number of fields, no tag will be
produced for it, in order to keep the size of the tags reasonable.
                        


\end{description}

\subsection{Call Graph Tagger ({\tt jap.cgtagger})}

The Call Graph Tagger produces LinkTags based on the call
graph. The Eclipse plugin uses these tags to produce
linked popup lists which indicate the source and target methods
of the statement. Selecting a link from the list moves the
cursor to the indicated method.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{Parity Tagger ({\tt jap.parity})}

The Parity Tagger produces StringTags and ColorTags indicating
the parity of a variable (even, odd, top, or bottom).  The eclipse
plugin can use tooltips and variable colouring to display the
information in these tags.  For example, even variables (such as
{\tt x} in {\tt x = 2}) are coloured yellow.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{Parameter Alias Tagger ({\tt jap.pat})}
For each method with parameters of reference type, this tagger indicates the aliasing relationships between the parameters using colour tags. Parameters that may be aliased are the same colour. Parameters that may not be aliased are in different colours.

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{Live Variables Tagger ({\tt jap.lvtagger})}
Colors live variables.

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{Reaching Defs Tagger ({\tt jap.rdtagger})}
For each use of a local in a stmt creates a link to the reaching def.

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{Cast Elimination Check Tagger ({\tt jap.che})}
Indicates whether cast checks can be eliminated.

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{Unreachable Method Transformer ({\tt jap.umt})}
When the whole-program analysis determines a method to be unreachable, this transformer inserts an assertion into the method to check that it is indeed unreachable.

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{Loop Invariant Tagger ({\tt jap.lit})}
An expression whose operands are constant or have reaching definitions from outside the loop body are tagged as loop invariant.

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{Available Expressions Tagger ({\tt jap.aet})}
A each statement a set of available expressions is after the statement is added as a tag.

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\item[Kind ({\tt kind})]
(default value: {\tt optimistic})







Possible values:\\
\begin{longtable}{p{1in}p{4in}}

{\tt optimistic }
&
\\

{\tt pessimistic }
&
\\

\end{longtable}


\end{description}

\subsection{Dominators Tagger ({\tt jap.dmt})}
Provides link tags at a statement to all of the satements dominators.

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\section{Grimp Body Creation ({\tt gb})}

The Grimp Body Creation phase creates a {\tt GrimpBody} for
each source method. It is run only if the output format is
{\tt grimp} or {\tt grimple}, or if class files are being
output and the Via Grimp option has been specified.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Grimp Pre-folding Aggregator ({\tt gb.a1})}

The Grimp Pre-folding Aggregator combines some local variables,
finding definitions with only a single use and removing the
definition after replacing the use with the definition's
right-hand side, if it is safe to do so. While the mechanism is
the same as that employed by the Jimple Local Aggregator, there
is more scope for aggregation because of Grimp's more complicated
expressions.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Only Stack Locals ({\tt only-stack-locals})]
(default value: {\tt true})




Aggregate only values stored in stack locals.



\end{description}

\subsection{Grimp Constructor Folder ({\tt gb.cf})}

The Grimp Constructor Folder combines {\tt new} statements
with the {\tt specialinvoke} statement that calls the new
object's constructor. For example, it turns

\begin{quote}\begin{verbatim}

r2 = new java.util.ArrayList;
r2.<init>();

\end{verbatim}\end{quote}

into

\begin{quote}\begin{verbatim}

r2 = new java.util.ArrayList();

\end{verbatim}\end{quote}



\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Grimp Post-folding Aggregator ({\tt gb.a2})}

The Grimp Post-folding Aggregator combines local variables after
constructors have been folded. Constructor folding typically
introduces new opportunities for aggregation, since when a
sequence of instructions like

\begin{quote}\begin{verbatim}

r2 = new java.util.ArrayList;
r2.<init>();
r3 = r2

\end{verbatim}\end{quote}
is replaced by

\begin{quote}\begin{verbatim}

r2 = new java.util.ArrayList();
r3 = r2

\end{verbatim}\end{quote}
the invocation of {\tt \ensuremath{<}init\ensuremath{>}} no longer represents a potential side-effect 
separating the two definitions, so they can be combined into

\begin{quote}\begin{verbatim}

r3 = new java.util.ArrayList();

\end{verbatim}\end{quote}
(assuming there are no subsequent uses of {\tt r2}).


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Only Stack Locals ({\tt only-stack-locals})]
(default value: {\tt true})




Aggregate only values stored in stack locals.



\end{description}

\subsection{Grimp Unused Local Eliminator ({\tt gb.ule})}

This phase removes any locals that are unused after constructor
folding and aggregation.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\section{Grimp Optimization ({\tt gop})}

The Grimp Optimization pack performs optimizations on
{\tt GrimpBody}s (currently there are no optimizations
performed specifically on {\tt GrimpBody}s, and the pack is
empty). It is run only if the output format is {\tt grimp} or
{\tt grimple}, or if class files are being output and the Via
Grimp option has been specified.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\section{Baf Body Creation ({\tt bb})}

The Baf Body Creation phase creates a
{\tt BafBody} from each source method. It is
run if the output format is {\tt baf} or {\tt b}, or
if class files are being output and the Via Grimp option
has not been specified.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Load Store Optimizer ({\tt bb.lso})}

The Load Store Optimizer replaces some combinations of loads to and stores from local variables with stack instructions. A simple example would be the replacement of

\begin{quote}\begin{verbatim}

store.r $r2;
load.r $r2;

\end{verbatim}\end{quote}

with 

\begin{quote}\begin{verbatim}

dup1.r

\end{verbatim}\end{quote}

in cases where the value of {\tt \$r2} is not used subsequently.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Debug ({\tt debug})]
(default value: {\tt false})




Produces voluminous debugging output describing the progress of
the load store optimizer.



\item[Inter ({\tt inter})]
(default value: {\tt false})




Enables two simple inter-block optimizations which attempt to
keep some variables on the stack between blocks.  Both are
intended to catch {\tt if}-like constructions where control
flow branches temporarily into two paths that converge at a later
point.



\item[sl ({\tt sl})]
(default value: {\tt true})




Enables an optimization which attempts to eliminate
{\tt store}/{\tt load} pairs.



\item[sl2 ({\tt sl2})]
(default value: {\tt false})




Enables an a second pass of the optimization which attempts to
eliminate {\tt store}/{\tt load} pairs.



\item[sll ({\tt sll})]
(default value: {\tt true})




Enables an optimization which attempts to eliminate 
{\tt store}/{\tt load}/{\tt load}
trios with some variant of {\tt dup}.



\item[sll2 ({\tt sll2})]
(default value: {\tt false})




Enables an a second pass of the optimization which attempts to
eliminate {\tt store}/{\tt load}/{\tt load} trios with
some variant of {\tt dup}.



\end{description}

\subsection{Peephole Optimizer ({\tt bb.pho})}

Applies peephole optimizations to the Baf intermediate
representation.  Individual optimizations must be implemented by
classes implementing the {\tt Peephole} interface. The
Peephole Optimizer reads the names of the {\tt Peephole}
classes at runtime from the file {\tt peephole.dat} and loads
them dynamically. Then it continues to apply the
{\tt Peephole}s repeatedly until none of them are able to
perform any further optimizations.

\par

Soot provides only one {\tt Peephole}, named
{\tt ExamplePeephole}, which is not enabled by the delivered
{\tt peephole.dat} file.
{\tt ExamplePeephole} removes all {\tt checkcast}
instructions.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Unused Local Eliminator ({\tt bb.ule})}

This phase removes any locals that are unused after load store optimization
and peephole optimization.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Local Packer ({\tt bb.lp})}

The Local Packer attempts to minimize the number of local
variables required in a method by reusing the same variable for
disjoint DU-UD webs. Conceptually, it is the inverse of the
Local Splitter.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Unsplit Original Locals ({\tt unsplit-original-locals})]
(default value: {\tt false})




Use the variable names in the original source as a guide when
determining how to share local variables across non-interfering
variable usages. This recombines named locals which were split by
the Local Splitter. 



\end{description}

\section{Baf Optimization ({\tt bop})}

The Baf Optimization pack performs optimizations on
{\tt BafBody}s (currently there are no optimizations performed
specifically on {\tt BafBody}s, and the pack is empty). It is
run only if the output format is {\tt baf} or {\tt b}, or
if class files are being output and the Via Grimp option
has not been specified.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\section{Tag Aggregator ({\tt tag})}


\par

The Tag Aggregator pack aggregates tags attached to individual units
into a code attribute for each method, so that these attributes can be
encoded in Java class files.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Line Number Tag Aggregator ({\tt tag.ln})}


\par

The Line Number Tag Aggregator aggregates line number
tags.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Array Bounds and Null Pointer Check Tag Aggregator ({\tt tag.an})}


\par

The Array Bounds and Null Pointer Tag Aggregator aggregates
tags produced by the Array Bound Checker and Null Pointer Checker.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{Dependence Tag Aggregator ({\tt tag.dep})}


\par

The Dependence Tag Aggregator aggregates
tags produced by the Side Effect Tagger.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{Field Read/Write Tag Aggregator ({\tt tag.fieldrw})}

The Field Read/Write Tag Aggregator aggregates field read/write
tags produced by the Field Read/Write Tagger, phase
{\tt jap.fieldrw}.


\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\section{Dava Body Creation ({\tt db})}

The decompile (Dava) option is set using the -f dava options in Soot.
Options provided by Dava are added to this dummy phase so as not to clutter the soot general arguments.
-p db (option name):(value) will be used to set all required values for Dava. 
                                

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\item[Source ({\tt source-is-javac})]
(default value: {\tt true})




					check out soot.dava.toolkits.base.misc.ThrowFinder
					In short we want to ensure that if there are throw exception info in the class file dava uses this info.					
					


\end{description}

\subsection{Transformations ({\tt db.transformations})}

					The transformations implemented using AST Traversal and structural flow analses on Dava's AST
					

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Renamer ({\tt db.renamer})}
If set, the renaming analyses implemented in Dava are applied to each method body being decompiled. The analyses use heuristics to choose potentially better names for local variables. (As of February 14th 2006, work is still under progress on these analyses (dava.toolkits.base.renamer).
					

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt false})






\end{description}

\subsection{De-obfuscate ({\tt db.deobfuscate})}
Certain analyses make sense only when the bytecode is obfuscated code. 
There are plans to implement such analyses and apply them on methods only if this flag is set. 
Dead Code elimination which includes removing code guarded by some condition which is always false or always true is one such
analysis. Another suggested analysis is giving default names to classes and fields. Onfuscators love to use weird names
for fields and classes and even a simple re-naming of these could be a good help to the user. 
Another more advanced analysis would be to check for redundant constant fields added by obfuscators and then remove uses 
of these constant fields from the code.

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}

\subsection{Force Recompilability ({\tt db.force-recompile})}
While decompiling we have to be clear what our aim is: do we want to convert bytecode
to Java syntax and stay as close to the actual execution of bytecode or do we want recompilably Java source representing
the bytecode. This distinction is important because some restrictions present in Java source are absent from the bytecode.
Examples of this include that fact that in Java a call to a constructor or super needs to be the first statement in
a constructors body. This restriction is absent from the bytecode. Similarly final fields HAVE to be initialized
once and only once in either the static initializer (static fields) or all the constructors (non-static fields). Additionally
the fields should be initialized on all possible execution paths. These restrictions are again absent from the bytecode.
In doing a one-one conversion of bytecode to Java source then no attempt should be made to fix any of these and similar problems
in the Java source. However, if the aim is to get recompilable code then these and similar issues need to be fixed. 
Setting the force-recompilability flag will ensure that the decompiler tries its best to produce recompilable Java source.

\paragraph{Accepted phase options:} 

\begin{description}

\item[Enabled ({\tt enabled})]
(default value: {\tt true})






\end{description}


\end{document}

